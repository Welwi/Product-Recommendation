{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "from utilities import DfLowMemory\n",
    "from utilities import CleanData\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from category_encoders import WOEEncoder, TargetEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DfLowMemory('train_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_empleado - 27734. Employee index: A active, B ex employed, F filial, N not employee, P pasive. \n",
    "#I am noticing that there is a value that is not in the description so I believe it is a typo. \n",
    "#I tried looking more into the data but in the end I decided to drop since it is just one person.\n",
    "\n",
    "df = df[df['ind_empleado'] != 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pais_residencia - 27734. One aspect that I found interesting is that customers with pais_residenciamissing had all other features missing. \n",
    "#For now I am going to drop all of them\n",
    "\n",
    "df.dropna(subset=['pais_residencia'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now there are 70 missing values for gender. The value distribution doesn't seem very different. I am going to replace them with the mode.\n",
    "df['sexo'].fillna(df['sexo'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ult_fec_cli_1t has a lot of missing values. This represents the last day the the customer was the primary costumer.\n",
    "# Looking at the indrel_1mes column, it shows that most of the customers at the beginning of the month were the primary costumers. So \n",
    "# I am assuming that the customers with missing last date as the primary costumers are still the primary costumers. So I am going to impute \n",
    "# this with 'primary'\n",
    "# THIS NEEDS TO BE MODIFIED TO TYPE DATE\n",
    "df.loc[df['ult_fec_cli_1t'].isnull(), 'ult_fec_cli_1t'] = 'PRIMARY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer type at the beginning of the month ,1 (First/Primary customer), 2 (co-owner ),P (Potential),3 (former primary), 4(former co-owner).\n",
    "# some values that were supposed to be 1 are 1.0 and for the other categories as well. So I am going to use 1,2,3,4 like in the description\n",
    "# This has been suggested by @StephenSmith\n",
    "map_dict = {'1.0' : '1',\n",
    "            '1' : '1',\n",
    "            '2' : '2',\n",
    "            '2.0' : '2',\n",
    "            '3' : '3',\n",
    "            '3.0' : '3', \n",
    "            '4' : '4',\n",
    "            '4.0' : '4'}\n",
    "\n",
    "df.indrel_1mes.fillna('P', inplace=True)\n",
    "df.indrel_1mes = df.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n",
    "df.indrel_1mes = df.indrel_1mes.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer relation type at the beginning of the month, A (active), I (inactive), P (former customer),R (Potential)\n",
    "# There are some described as N that doesn't fit into the column description.\n",
    "# Taking a closer look at these 4 rows and comparing them with the ind_actividad: df[df['tiprel_1mes'] == 'N'].iloc[:,8:24]\n",
    "# The ones that had ind_actividad = 1 were imputed as active and the ones that had 0 were imputed as I\n",
    "# For the nan values, there is another column named 'ind_actividad_cliente' that is 1 for active costumers and 0 for inactive. I am \n",
    "# going to use this to impute the nan values for tiprel_1mes\n",
    "\n",
    "df.loc[df['tiprel_1mes'].isnull(), 'tiprel_1mes'] = df['ind_actividad_cliente']\n",
    "\n",
    "map_tip = {1 : 'A',\n",
    "           0 : 'I'}        \n",
    "\n",
    "df.tiprel_1mes = df.tiprel_1mes.apply(lambda x: map_tip.get(x,x))\n",
    "df.loc[6603017, 'tiprel_1mes'] = 'A'\n",
    "df.loc[10123924, 'tiprel_1mes'] = 'A'\n",
    "df.loc[10124648, 'tiprel_1mes'] = 'I'\n",
    "df.loc[11247349, 'tiprel_1mes'] = 'I'\n",
    "\n",
    "df.tiprel_1mes = df.tiprel_1mes.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conyuemp Spouse index. 1 if the customer is spouse of an employee\n",
    "# I am assuming that most customers are not spouses and I am going to impute these with the mode\n",
    "# Now there are 70 missing values for gender. The value distribution doesn't seem very different. I am going to replace them with the mode.\n",
    "df['conyuemp'].fillna(df['conyuemp'].mode()[0], inplace=True)\n",
    "df.conyuemp = df.conyuemp.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canal_entrada. Channel used by the customer to join\n",
    "# I am going to fill the missing values with the mode\n",
    "df['canal_entrada'].fillna(df['canal_entrada'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipodom. Addres type. 1, primary address. It is only 1 value missing so I am just going to replace it with the mode\n",
    "df['tipodom'].fillna(df['tipodom'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_prov. Province code (customer's address)\n",
    "# nomprov. Province name. \n",
    "# These two have the same number of missing values. I am going to replace these with unknow\n",
    "# THESE IS SUGGESTED BY ALAN PRYOR\n",
    "\n",
    "for c in ['cod_prov', 'nomprov']:\n",
    "    df.loc[df[c].isnull(), c ] = 'UNKOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renta. Gross income of the household. I am going to replace the missing values with the mean salary per providence. \n",
    "\n",
    "salaries = dict(df.groupby('nomprov')['renta'].mean().round(0))\n",
    "df.loc[df['renta'].isnull(), 'renta'] = df['nomprov']\n",
    "df.renta = df.renta.apply(lambda x: salaries.get(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmento. segmentation: 01 - VIP, 02 - Individuals 03 - college graduated\n",
    "for c in ['segmento']:\n",
    "    df.loc[df[c].isnull(), c ] = 'UNKOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ind_nomina_ult1'].fillna(df['ind_nomina_ult1'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ind_nom_pens_ult1'].fillna(df['ind_nom_pens_ult1'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha_dato'] = pd.to_datetime(df['fecha_dato'], format=\"%Y-%m-%d\")\n",
    "df['fecha_alta'] = pd.to_datetime(df['fecha_alta'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['antiguedad'] == '-999999', 'antiguedad'] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values and action plan\n",
    "\n",
    "ind_empleado - 27734. Employee index: A active, B ex employed, F filial, N not employee, P pasive. I am noticing that there is a value that is not in the description so I believe it is a typo. I tried looking more into the data but in the end I decided to drop since it is just one person. The nan values I am replacing with the mode which in this case it is that the person is not an employee.\n",
    "\n",
    "df = df[df['ind_empleado'] != 'S']\n",
    "\n",
    "-------------------------------------------------------\n",
    "pais_residencia - 27734. One aspect that I found interesting is that customers with pais_residenciamissing had all other features missing. For now I am going to drop all of them\n",
    "\n",
    "filtered_df = df[df['pais_residencia'].isnull()]\n",
    "len(filtered_df['ncodpers'].unique())\n",
    "This shows that there are 7340 without much information about them\n",
    "\n",
    "-------------------------------------------------------\n",
    "sexo - 27804. Most of the clients that have this information missing dont have much information on them overall. If we were to drop the ones that have most information missing, sexo would have about 70 values missing. For now I am going to change these with the mode.\n",
    "\n",
    "-------------------------------------------------------\n",
    "I need to turn fecha_dato and fecha_alta into dates\n",
    "\n",
    "fecha_alta - 27734. This is the date that the customer joined the bank.\n",
    "Added another column called month. May be useful in the case that some customers buy more depending on the time of the year.\n",
    "\n",
    "-------------------------------------------------------\n",
    "ult_fec_cli_1t - 13622516. This is the last date as a primary customer.\n",
    "indrel_1mes                149781\n",
    "tiprel_1mes                149781\n",
    "indresi                     27734\n",
    "indext                      27734\n",
    "conyuemp                 13645501\n",
    "canal_entrada              186126\n",
    "indfall                     27734\n",
    "tipodom                     27735\n",
    "cod_prov                    93591\n",
    "nomprov                     93591\n",
    "ind_actividad_cliente       27734\n",
    "renta                     2794375\n",
    "segmento                   189368\n",
    "ind_nomina_ult1             16063\n",
    "ind_nom_pens_ult1           16063\n",
    "\n",
    "\n",
    "-------------------------------------------------------\n",
    "A bank guarantee is a lending institution's promise to cover a loss if a borrower (their customer) defaults on a debt to a third party. \n",
    "\n",
    "A payroll account is a separate bank account for your business that is strictly used for payroll. Instead of lumping all your business expenses into one account, you will pay employee wages with your payroll bank account. The money going into the payroll account will only be used for payroll.\n",
    "\n",
    "Bank policy requires that account owners be the legal age of 18 in order to open an account online. If you are not 18 years old, you may open an account for minors with your parent or legal guardian as the joint account holder.\n",
    "\n",
    "A pension plan is a type of retirement plan where an employee adds money into a fund that includes contributions by the employer.\n",
    "\n",
    "A securities account sometimes known as a brokerage account is an account that holds financial assets such as securities on behalf of an investor with a bank, broker or custodian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in df.columns.tolist() if c not in ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    " 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like 1st place solution mentioned, some features worth exploring are lags of products time since presence of products, average of products, time since last purchase\n",
    "# of products\n",
    "# time since change and lads for a non-product attributes: segmento, indactividadclient, codprov, canalentrada, indrel1mes, tiprel1mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for dato in df['fecha_dato'].unique().tolist():\n",
    "    # get 10% sample for each day\n",
    "    df_dato = df.loc[df['fecha_dato'] == dato].copy().sample(frac=0.10)\n",
    "\n",
    "    # add to frames list\n",
    "    frames.append(df_dato)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['fecha_dato'] = pd.to_datetime(trial['fecha_dato'], format=\"%Y-%m-%d\")\n",
    "trial['fecha_alta'] = pd.to_datetime(trial['fecha_alta'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x= trial['fecha_dato'], y=trial['ind_ahor_fin_ult1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['month'] = trial['fecha_dato'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['YearMonth'] = trial['fecha_dato'].map(lambda x: 100*x.year + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha_dato'] = pd.to_datetime(df['fecha_dato'], format=\"%Y-%m-%d\")\n",
    "df['fecha_alta'] = pd.to_datetime(df['fecha_alta'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearMonth'] = df['fecha_dato'].map(lambda x: 100*x.year + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x= df['YearMonth'], y = df['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['JoinYear'] = trial['fecha_alta'].apply(lambda x: 100*x.year + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = trial.groupby('ncodpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x= df['JoinYear'], y = df['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customer = list(set(trial['ncodpers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust_join_date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer in new_customer:\n",
    "    new_customer_join_date.append(trial['fecha_alta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months = pd.DataFrame(pd.Series(trial.fecha_dato.unique())).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months[\"month_id\"] = pd.Series(range(1,1+unique_months.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months[\"month_next_id\"] = 1 + unique_months[\"month_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months.rename(columns={0:\"fecha_dato\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a recommendation system first we need a distance metric so that we can find users who are similar to a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    " 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in trial.columns.tolist() if c not in [target, 'fecha_dato', 'fecha_alta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trial[used_cols].values\n",
    "y = trial[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TargetEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for c in trial[ohe]:\n",
    "    print(c)\n",
    "    print(trial[c].unique())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t in target:\n",
    "    X = trial[used_cols]\n",
    "    y = trial[t]\n",
    "    \n",
    "    encoder = TargetEncoder()\n",
    "    X = encoder.fit_transform(X,y)\n",
    "    \n",
    "    model = X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trial[used_cols].values\n",
    "y = trial['ind_ahor_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoder.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "train_size = int(len(X) * 0.7)\n",
    "y_train = int(len(y) * 0.7)\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "y_train, y_test = y[0:train_size], y[train_size:len(X)]\n",
    "print('Observations: ', (len(X)))\n",
    "print('Training Observations: ', (len(train)))\n",
    "print('Testing Observations: ', (len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imb_xgb(special_objective='weighted', imbalance_alpha=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building the 24 models\n",
    "\n",
    "predictions = []\n",
    "models = []\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "for t in target:\n",
    "    X = trial[used_cols].values\n",
    "    y = trial[t]\n",
    "    \n",
    "    X = encoder.fit_transform(X,y)\n",
    "    \n",
    "    train_size = int(len(X) * 0.7)\n",
    "    y_train = int(len(y) * 0.7)\n",
    "    X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "    y_train, y_test = y[0:train_size], y[train_size:len(X)]\n",
    "    \n",
    "    model = imb_xgb(special_objective='weighted', imbalance_alpha=2)\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test.values)\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_predictions = []\n",
    "for y_pred in predictions:\n",
    "    y_pred = (y_pred - y_pred.min())/(y_pred.max() - y_pred.min())\n",
    "    y_pred.min(), y_pred.max()\n",
    "    zero_one_predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.array(trial[train_size:]['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argsort(zero_one_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.fliplr(preds)[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.array(pd.read_csv('test_ver2.csv', usecols=['ncodpers'])['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    \n",
    "    cust = test_id[i]\n",
    "    top_products = target[pred]\n",
    "    used_products = customer_dict.get(cust,[])\n",
    "    \n",
    "    new_top_products = []\n",
    "    \n",
    "    for product in top_products: \n",
    "        if product not in used_products:\n",
    "            new_top_products.append(product)\n",
    "        if len(new_top_products) == 7:\n",
    "            break\n",
    "    final_preds.append(\" \".join(new_top_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "submission.to_csv(kaggle_submission, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lags\n",
    "\n",
    "Lagging of independent variables is often necessary in order for the regression model to be able to predict the future--i.e., to predict what will happen in period t based on knowledge of what happened up to period t-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling without train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    " 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in trial.columns.tolist() if c not in [target, 'fecha_dato', 'fecha_alta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "models = []\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "for t in target:\n",
    "    X = trial[used_cols].values\n",
    "    y = trial[t]\n",
    "    \n",
    "    X = encoder.fit_transform(X,y)\n",
    "    \n",
    "    model = imb_xgb(special_objective='weighted', imbalance_alpha=2)\n",
    "    model.fit(X.values, y.values)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test.values)\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(trial[train_size:][target].values, np.array(zero_one_predictions).T, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [c for c in df.columns.tolist() if c not in target + ['ncodpers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = trial.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = customer_id.drop_duplicates('ncodpers', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dict = {}\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id.set_index('ncodpers', inplace=True)\n",
    "customer_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in customer_id.columns.tolist():\n",
    "    customer_id[c] = customer_id[c].astype(bool)\n",
    "    \n",
    "customer_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in customer_id.iterrows():\n",
    "    cust = row['ncodpers']\n",
    "    used_products = set(target[np.array(row[1:])==1])\n",
    "    customer_dict[cust] = used_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apk(y_test, y_pred, k=7):\n",
    "    \n",
    "    # adjust the length if necessary\n",
    "    if len(y_pred) > k:\n",
    "        y_pred = y_pred[:k]\n",
    "        \n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i, p in enumerate(y_pred):\n",
    "        if p in y_test and p not in y_pred[:i]:\n",
    "            num_hits += num_hits / (i+1.0)\n",
    "            \n",
    "        if not y_test:\n",
    "            return 0.0\n",
    "        \n",
    "    return score / min(len(y_test), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk (y_test,y_pred, k=7):\n",
    "    \n",
    "    return np.mean([_apk(a,p,k) for a,p in zip(y_test, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapk(y_test, zero_one_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapk(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to find the products that customers do not have\n",
    "# if user has every product nothing should be recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_test, y_pred > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second target\n",
    "X = trial[used_cols].values\n",
    "y = trial['ind_aval_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TargetEncoder()\n",
    "X = encoder.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = imb_xgb(special_objective='weighted', imbalance_alpha=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred2 > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building the 24 models\n",
    "\n",
    "predictions = []\n",
    "models = []\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "for t in target:\n",
    "    X = trial[used_cols].values\n",
    "    y = trial[t]\n",
    "    \n",
    "    X = encoder.fit_transform(X,y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    model = imb_xgb(special_objective='weighted', imbalance_alpha=2)\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test.values)\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in customer_id.iterrows():\n",
    "    cust = row['ncodpers']\n",
    "    used_products = set(target[np.array(row[1:])==1])\n",
    "    customer_dict[cust] = used_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tprint(\"Getting the top products..\")\n",
    "\ttarget_cols = np.array(target_cols)\n",
    "\tpreds = np.argsort(preds, axis=1)\n",
    "\tpreds = np.fliplr(preds)[:,:7]\n",
    "\ttest_id = np.array(pd.read_csv(data_path + \"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "\tfinal_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "\tout_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "\tout_df.to_csv('sub_xgb_new.csv', index=False)\n",
    "\tprint(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
