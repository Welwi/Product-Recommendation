{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "from utilities import DfLowMemory\n",
    "from utilities import CleanData\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from category_encoders import WOEEncoder, TargetEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = DfLowMemory('train_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = CleanData(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From BreakfastPirate\n",
    "I’m only training on about 37,000 accounts – only the accounts that added a new product in June 2015. I found that the distribution of products added varied a lot by month, and June seemed to be an unusual month. Since we are predicting June 2016, I trained on only June 2015.\n",
    "\n",
    "I only used accounts that added a new product in June 2015. We are not trying to determine who will add a new product, we are only trying to predict which products they would add if they did. So I excluded all accounts that didn’t add a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only May2015, June2015, May2016 \n",
    "\n",
    "df_train_may15 = df_train[df_train['fecha_dato'] == '2015-05-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_June15 = df_train[df_train['fecha_dato'] == '2015-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_may16 = df_train[df_train['fecha_dato'] == '2016-05-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = pd.merge(df_train_June15, df_train_may15, how='left', on='ncodpers', suffixes=('','_may'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the features with _prev\n",
    "todrop = [c for c in df15.columns if '_may' in c and '_ult1' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df15.drop(columns=todrop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_targets = [c for c in df15.columns if '_ult1_may' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [c for c in df15.columns if '_ult' in c and '_ult1_may' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, using the idea proposed by BreakFastPirate, I am going to drop any rows that did not add a new product in June2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df15.isnull().sum()\n",
    "# There are some null values on some customers in May. This is because in May they were not customers yet. So I am going to fill those with 0\n",
    "\n",
    "may_customers = [col for col in df15.columns.tolist() if col in may_targets]\n",
    "june_customers = [col for col in df15.columns.tolist() if col in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, using the idea proposed by BreakFastPirate, I am going to keep only the accounts that added a new product in June 2015\n",
    "# it makes sense to me that most customers have chosen to keep the services that they had without acquiring new ones. It went from 630248 to 33312\n",
    "def new_product(x):\n",
    "    for col in june_customers:\n",
    "        # dropping when they are equal and when they dropped the product\n",
    "        if x[col+'_may'] < x[col]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df15['new_product'] = df15.apply(new_product, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df15= df15[df15['new_product'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33312, 73)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting only the users that were present on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = DfLowMemoryTest('test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby('nomprov')['renta'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to save the cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in csv.DictReader(in_file_name):\n",
    "\t\t# use only the four months as specified by breakfastpirate #\n",
    "\t\tif row['fecha_dato'] not in ['2015-05-28', '2015-06-28', '2016-05-28', '2016-06-28']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in customer_id.iterrows():\n",
    "    cust = row['ncodpers']\n",
    "    used_products = set(target[np.array(row[1:])==1])\n",
    "    customer_dict[cust] = used_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have the customer in the test set\n",
    "# drop customers who mantained the product (this is only during modeling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    " 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in trial.columns.tolist() if c not in [target, 'fecha_dato', 'fecha_alta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "models = []\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "for t in target:\n",
    "    X = trial[used_cols].values\n",
    "    y = trial[t]\n",
    "    \n",
    "    X = encoder.fit_transform(X,y)\n",
    "    \n",
    "    train_size = int(len(X) * 0.7)\n",
    "    y_train = int(len(y) * 0.7)\n",
    "    X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "    y_train, y_test = y[0:train_size], y[train_size:len(X)]\n",
    "    \n",
    "    model = imb_xgb(special_objective='weighted', imbalance_alpha=2)\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test.values)\n",
    "    predictions.append(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
